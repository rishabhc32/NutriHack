# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hQtF0aNHCvlGFEK3rXnBB7dUUQwaqBHt
"""

!pip install -U -q PyDrive

from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

# 1. Authenticate and create the PyDrive client.
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

downloaded = drive.CreateFile({'id':'1itm9DpwiOVAPisJ21q2EL-tzOQgYRsqJ'})
downloaded.GetContentFile('train.csv')
downloaded = drive.CreateFile({'id':'1f7XFXcvcvnNPbk1gl_SPnSUL8eS4zLpr'})
downloaded.GetContentFile('test.csv')

import numpy as np
import keras
from keras import layers
from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D
from keras.models import Model, load_model
from keras.models import Sequential
from keras.models import model_from_json

def load_train_data_NPY():
    data = np.load('train_data.npy')
    return data

def load_test_data_NPY():
    data = np.load('test_data.npy')
    return data

train_data= load_train_data_NPY()

test_data = load_test_data_NPY()

IMG_SIZE = 280
LR = 1e-3
#MODEL_NAME = 'quickest.model'.format(LR, '2conv-basic')


train_data= data.load_train_data()
train = train_data[:-200]
test = train_data[-200:]

X = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,1)
Y = [i[1] for i in train]
test_x = np.array([i[0] for i in test]).reshape(-1,IMG_SIZE,IMG_SIZE,1)
test_y = [i[1] for i in test]
X = X.reshape([-1, 280, 280, 1])
test_x = test_x.reshape([-1, 280, 280, 1])

model = Sequential()

model.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1),padding = 'same', activation='relu', input_shape=(280, 280, 1)))
model.add(MaxPooling2D(pool_size=(5, 5),padding = 'same'))

model.add(Conv2D(64, kernel_size=(5, 5), strides=(1, 1),padding = 'same', activation='relu'))
model.add(MaxPooling2D(pool_size=(5, 5),padding = 'same'))

model.add(Conv2D(128, kernel_size=(5, 5), strides=(1, 1),padding = 'same', activation='relu'))
model.add(MaxPooling2D(pool_size=(5, 5),padding = 'same'))

model.add(Conv2D(64, kernel_size=(5, 5), strides=(1, 1),padding = 'same', activation='relu'))
model.add(MaxPooling2D(pool_size=(5, 5),padding = 'same'))

model.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1),padding = 'same', activation='relu'))
model.add(MaxPooling2D(pool_size=(5, 5),padding = 'same'))

model.add(Flatten())
model.add(Dense(1024, activation='relu'))
model.add(Dense(5, activation='softmax'))

model.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam',metrics=['accuracy'])

import pandas as pd

train_df = pd.read_csv('train.csv')
test_df = pd.read_csv('test.csv')

train_df.head()

import pandas as pd

train_df = pd.read_csv('train.csv')
test_df = pd.read_csv('test.csv')

#add numpy array as train_data,test_data from train_df and test_df

train = train_data[:-200]
test = train_data[-200:]

X = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,1)
Y = [i[1] for i in train]
test_x = np.array([i[0] for i in test]).reshape(-1,IMG_SIZE,IMG_SIZE,1)
test_y = [i[1] for i in test]
X = X.reshape([-1, 280, 280, 1])
test_x = test_x.reshape([-1, 280, 280, 1])

